#!/usr/bin/env python3
"""
æ„å»ºè„šæœ¬ - å°† JSON æ•°æ®è½¬æ¢ä¸º Markdown æ–‡æ¡£

ç”¨æ³•:
    python build.py

æ­¤è„šæœ¬ä¼šè¯»å– data/ ç›®å½•ä¸‹çš„ JSON æ•°æ®æ–‡ä»¶ï¼Œ
ç”Ÿæˆå¯¹åº”çš„ Markdown æ–‡ä»¶åˆ° docs/ ç›®å½•ã€‚
"""

import json
import sys
from pathlib import Path
from datetime import datetime
from zoneinfo import ZoneInfo

from app.config import CATEGORIES

# é¡¹ç›®è·¯å¾„
PROJECT_ROOT = Path(__file__).parent
DATA_DIR = PROJECT_ROOT / "data"
DOCS_DIR = PROJECT_ROOT / "docs"


def load_json(file_path: Path) -> list:
    """åŠ è½½ JSON æ–‡ä»¶"""
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        return data if isinstance(data, list) else []
    except (FileNotFoundError, json.JSONDecodeError) as e:
        print(f"è­¦å‘Š: æ— æ³•åŠ è½½ {file_path}: {e}")
        return []

def _build_examples_section(examples: list) -> list:
    """æ„å»ºä¾‹å¥éƒ¨åˆ†çš„ Markdown"""
    lines = []
    if examples:
        lines.append("- **ä¾‹å¥**ï¼š")
        lines.append("")
        for ex in examples:
            html_text = ex.get("html", ex.get("jp", ""))
            cn = ex.get("cn", "")
            lines.append('    > <div class="example-box">')
            lines.append(f"    > {html_text}")
            lines.append(f"    > <br><small>{cn}</small>")
            lines.append("    > </div>")
            lines.append("")
    return lines

def _build_notes_section(notes: str) -> list:
    """æ„å»ºå¤‡æ³¨éƒ¨åˆ†çš„ Markdown"""
    lines = []
    if notes:
        lines.append(f"> ğŸ“ **å¤‡æ³¨**ï¼š")
        lines.append("")
        for line in notes.splitlines():
            lines.append(f"> {line}")
            lines.append("> ")
        lines.append("")
    return lines

def build_verbs_page(data: list) -> str:
    """æ„å»ºåŠ¨è¯é¡µé¢"""
    lines = [
        "# ğŸ”„ åŠ¨è¯",
        "",
        f"{CATEGORIES['verbs']['description']}ã€‚",
        "",
        f"å…± **{len(data)}** ä¸ªåŠ¨è¯",
        "",
        "---",
        ""
    ]

    if not data:
        lines.append("æš‚æ— æ•°æ®ã€‚")
        return "\n".join(lines)

    for item in data:
        display = item.get("word", item.get("reading", ""))
        reading = f"{item.get('display_html', '')}ï¼ˆ{item.get('reading', '')}ï¼‰"
        verb_type = item.get("type", "")
        meaning = item.get("meaning", "")

        lines.append(f"## {display}")
        lines.append("")
        lines.append(f"- **è¯»éŸ³**ï¼š{reading}")
        lines.append(f"- **ç±»å‹**ï¼š{verb_type}")
        lines.append(f"- **é‡Šä¹‰**ï¼š{meaning}")
        lines.append("")

        examples = item.get("examples", [])
        lines.extend(_build_examples_section(examples))

        notes = item.get("notes", "")
        lines.extend(_build_notes_section(notes))

        lines.append("---")
        lines.append("")

    return "\n".join(lines)


def build_grammar_page(data: list) -> str:
    """æ„å»ºè¯­æ³•é¡µé¢"""
    lines = [
        "# ğŸ“ è¯­æ³•",
        "",
        f"{CATEGORIES['grammar']['description']}ã€‚",
        "",
        f"å…± **{len(data)}** æ¡è¯­æ³•",
        "",
        "---",
        ""
    ]

    if not data:
        lines.append("æš‚æ— æ•°æ®ã€‚")
        return "\n".join(lines)

    for item in data:
        display = item.get("title", item.get("display_html", ""))
        category = item.get("category", "")
        meaning = item.get("meaning", "")

        lines.append(f"## {display}")
        lines.append("")
        lines.append(f"- **ç±»åˆ«**ï¼š{category}")
        lines.append(f"- **å«ä¹‰**ï¼š{meaning}")
        lines.append("")

        usage = item.get("usage", [])
        if usage:
            lines.append("- **ç”¨æ³•**ï¼š")
            lines.append("")
            for u in usage:
                lines.append(f"    - {u}")
            lines.append("")

        examples = item.get("examples", [])
        lines.extend(_build_examples_section(examples))

        notes = item.get("notes", "")
        lines.extend(_build_notes_section(notes))

        lines.append("---")
        lines.append("")

    return "\n".join(lines)


def build_vocabulary_page(data: list) -> str:
    """æ„å»ºè¯æ±‡é¡µé¢"""
    lines = [
        "# ğŸ“š è¯æ±‡",
        "",
        f"{CATEGORIES['vocabulary']['description']}ã€‚",
        "",
        f"å…± **{len(data)}** ä¸ªè¯æ±‡",
        "",
        "---",
        ""
    ]

    if not data:
        lines.append("æš‚æ— æ•°æ®ã€‚")
        return "\n".join(lines)

    for item in data:
        display = item.get("word", item.get("reading", ""))
        reading = f"{item.get('display_html', '')}ï¼ˆ{item.get('reading', '')}ï¼‰"
        word_type = item.get("type", "")
        meaning = item.get("meaning", "")

        lines.append(f"## {display}")
        lines.append("")
        lines.append(f"- **è¯»éŸ³**ï¼š{reading}")
        lines.append(f"- **è¯æ€§**ï¼š{word_type}")
        lines.append(f"- **é‡Šä¹‰**ï¼š{meaning}")
        lines.append("")

        examples = item.get("examples", [])
        lines.extend(_build_examples_section(examples))

        notes = item.get("notes", "")
        lines.extend(_build_notes_section(notes))

        lines.append("---")
        lines.append("")

    return "\n".join(lines)


def build_index_page(stats: dict) -> str:
    """æ„å»ºé¦–é¡µ"""
    total = sum(stats.values())
    now = datetime.now(ZoneInfo("Asia/Shanghai")).strftime("%Y-%m-%d %H:%M")

    content = f"""# æ—¥è¯­ç¬”è®°

## ğŸ“Š å†…å®¹ç»Ÿè®¡

| ç±»åˆ« | æ•°é‡ |
|------|------|
| ğŸ”„ åŠ¨è¯ | {stats.get('verbs', 0)} |
| ğŸ“ è¯­æ³• | {stats.get('grammar', 0)} |
| ğŸ“š è¯æ±‡ | {stats.get('vocabulary', 0)} |
| **æ€»è®¡** | **{total}** |

<p><small style="color:#6b7280">æœ€åæ›´æ–°: {now} (UTC+8)</small></p>
"""
    return content


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ“š å¼€å§‹æ„å»ºæ—¥è¯­ç¬”è®°...")

    # ç¡®ä¿ç›®å½•å­˜åœ¨
    DOCS_DIR.mkdir(parents=True, exist_ok=True)

    # åŠ è½½æ•°æ®
    verbs = load_json(DATA_DIR / "verbs.json")
    grammar = load_json(DATA_DIR / "grammar.json")
    vocabulary = load_json(DATA_DIR / "vocabulary.json")

    stats = {
        "verbs": len(verbs),
        "grammar": len(grammar),
        "vocabulary": len(vocabulary)
    }

    # æ„å»ºé¡µé¢
    pages = {
        "index.md": build_index_page(stats),
        "verbs.md": build_verbs_page(verbs),
        "grammar.md": build_grammar_page(grammar),
        "vocabulary.md": build_vocabulary_page(vocabulary)
    }

    # å†™å…¥æ–‡ä»¶
    for filename, content in pages.items():
        file_path = DOCS_DIR / filename
        with open(file_path, "w", encoding="utf-8") as f:
            f.write(content)
        print(f"  âœ“ {filename}")

    print(f"\nâœ… æ„å»ºå®Œæˆï¼")
    print(f"   åŠ¨è¯: {stats['verbs']} æ¡")
    print(f"   è¯­æ³•: {stats['grammar']} æ¡")
    print(f"   è¯æ±‡: {stats['vocabulary']} æ¡")
    print(f"\nè¿è¡Œ 'mkdocs serve' é¢„è§ˆç½‘ç«™")


if __name__ == "__main__":
    main()
